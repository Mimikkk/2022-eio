{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projekt Autoenkoder\n",
    "Indeks: 145317\n",
    "\n",
    "Wymagania:\n",
    "- stworzenie sieci neuronowej typu autoencoder\n",
    "- dane wejściowe to obrazy czarno-białe (1 kanał)\n",
    "- dane wyjściowe to obrazy kolorowe (3 kanały)\n",
    "- badanie różnych rozmiarów sieci neuronowej\n",
    "- badanie wpływu poszczególnych elementów regularyzacji na wynik:\n",
    "  - wpływ parametru momentum oraz rozmiaru batcha przy wykorzystaniu batch normalization\n",
    "  - wpływ dropout rate\n",
    "  - wpływ weight decay\n",
    "\n",
    "Zrealizowane przy wykorzystaniu bibliotek:\n",
    "- Pytorch — Tworzenie i nauka sieci neuronowej.\n",
    "- Matplotlib -- Wizualizacja.\n",
    "- cv2 - open-cv -- Obróbka obrazów.\n",
    "\n",
    "Wykorzystany dataset:\n",
    "- [CIFAR-100](https://www.cs.toronto.edu/~kriz/cifar.html) -- Zbiór 50000 obrazów treningowych i 10000 testowych.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preludium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Dense, Input, Conv2D, Flatten, Reshape, Conv2DTranspose, BatchNormalization, Dropout\n",
    "from keras.models import Model\n",
    "from keras.callbacks import ReduceLROnPlateau, ModelCheckpoint\n",
    "from keras.datasets import cifar100\n",
    "from keras import Sequential\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sprawdzenie dostępności GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "print(\n",
    "  gpus := tf.config.list_physical_devices('GPU'),\n",
    "  gpus and 'GPU is available' or \"GPU is not available\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Załadowanie bazy obrazów Cifar100 oraz wykonanie preprocesów.\n",
    "- Baza obrazów:\n",
    "  - [CIFAR-100](https://www.cs.toronto.edu/~kriz/cifar.html) -- Zbiór 50000 obrazów treningowych i 10000 testowych.\n",
    "- Preprocesy:\n",
    "  - Zamiana przestrzeni z 1-255 python-int na 0-1 float32.\n",
    "  - Zamiana obrazu kolorowego na obraz szary.\n",
    "  - Rozszerzenie kształtu obrazu szarego na kształt kompatybilny z wejściem sieci."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rgb2gray(rgb):\n",
    "  return cv2.cvtColor(rgb, cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "def load_datasets():\n",
    "  print(\"Loading train dataset...\")\n",
    "  print(\"Loading test dataset...\")\n",
    "  (y_train, _), (y_test, _) = cifar100.load_data()\n",
    "  print(\"Preparing train dataset...\")\n",
    "  y_train = y_train.astype('float32') / 255\n",
    "  x_train = np.expand_dims([rgb2gray(x) for x in y_train], axis=3)\n",
    "  print(\"Preparing test dataset...\")\n",
    "  y_test = y_test.astype('float32') / 255\n",
    "  x_test = np.expand_dims([rgb2gray(x) for x in y_test], axis=3)\n",
    "  print(\"Finished.\")\n",
    "  return (x_train, y_train), (x_test, y_test)\n",
    "(x_train, y_train), (x_test, y_test) = load_datasets()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prezentacja przykładowych obrazów z datasetu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare(original, grayscale=None):\n",
    "  if grayscale is None: grayscale = rgb2gray(original)\n",
    "\n",
    "  figure, axes = plt.subplots(1, 2)\n",
    "  axes[0].set_title(\"Original\")\n",
    "  axes[0].grid(False)\n",
    "  axes[0].set_axis_off()\n",
    "  axes[0].imshow(original)\n",
    "  axes[1].set_title(\"Grayscale\")\n",
    "  axes[1].grid(False)\n",
    "  axes[1].set_axis_off()\n",
    "  axes[1].imshow(grayscale, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = np.random.randint(2, len(y_train) - 1)\n",
    "for original in y_train[index - 2:index]: compare(original)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prezentacja kolażu obrazów."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def square_collage(images, size: int = 8):\n",
    "  (_, rows, cols, channels) = images.shape\n",
    "  collage = images[:size * size]\n",
    "  collage = collage.reshape((size, size, rows, cols, channels))\n",
    "  return np.vstack([*map(np.hstack, collage)])\n",
    "\n",
    "compare(square_collage(y_test), square_collage(x_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Konstrukcja modelu sieci autoencoder.\n",
    "- Konstrukcja sieci jst sparametryzowana o możliwość wprowadzenia:\n",
    "  - use_normalization: bool -- batch normalization.\n",
    "  - use_dropout: bool | float -- wykorzystanie dropout'u.\n",
    "- Podczas trenowania sieci również są dostępne opcje:\n",
    "  - use_weight_decay: float -- wykorzystanie weight decay podczas nauki."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 'Encoder'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class Encoder(Model):\n",
    "  def __init__(self, layers_filters, use_normalization=False, use_dropout=False):\n",
    "    super().__init__(name='encoder')\n",
    "    def layers():\n",
    "      for filters in layers_filters:\n",
    "        yield Conv2D(filters, kernel_size=3, padding='same', activation='relu')\n",
    "        if use_normalization:\n",
    "          yield BatchNormalization()\n",
    "        if use_dropout:\n",
    "          yield Dropout(use_dropout)\n",
    "    self.net = Sequential(list(layers()))\n",
    "\n",
    "  def call(self, inputs):\n",
    "    return self.net(inputs)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Model 'Decoder'."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(Model):\n",
    "  def __init__(self, layers_filters):\n",
    "    super().__init__(name='decoder')\n",
    "    def layers():\n",
    "      for filters in reversed(layers_filters):\n",
    "        yield Conv2DTranspose(filters, kernel_size=3, padding='same', activation='relu')\n",
    "      yield Conv2DTranspose(3, kernel_size=3, padding='same', activation='sigmoid')\n",
    "\n",
    "    self.net = Sequential(list(layers()))\n",
    "\n",
    "  def call(self, inputs):\n",
    "    return self.net(inputs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Podsumowanie enkodera i dekodera"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "layers_filters = [32, 64, 128, 256]\n",
    "encoder = Decoder(layers_filters)\n",
    "encoder.build(input_shape=(None, None, None, 1))\n",
    "encoder.summary()\n",
    "decoder = Encoder(layers_filters)\n",
    "decoder.build(input_shape=(None, None, None, 3))\n",
    "decoder.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Podsumowanie autoenkodera"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Autoencoder(Model):\n",
    "  def __init__(self, layers_filters, use_normalization=False, use_dropout=False):\n",
    "    super().__init__(name='autoencoder')\n",
    "    def layers():\n",
    "      yield Encoder(layers_filters, use_normalization, use_dropout)\n",
    "      yield Decoder(layers_filters)\n",
    "    self.net = Sequential(list(layers()))\n",
    "  def call(self, inputs): return self.net(inputs)\n",
    "autoencoder = Autoencoder(layers_filters)\n",
    "autoencoder.build(input_shape=(None, None, None, 1))\n",
    "autoencoder.compile(loss='mse', optimizer='adam')\n",
    "autoencoder.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training callbacks\n",
    "- ReduceLROnPlateau - reduces lr by given value 0.1**0.5 every 3 epochs without improvement.\n",
    "- ModalCheckpoint - saves model to given path every improved epoch."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_addons as tfa\n",
    "\n",
    "def train_model(model, weight_decay=0, savename=None):\n",
    "  callbacks = [\n",
    "    ReduceLROnPlateau(factor=np.sqrt(0.1), cooldown=0, patience=3, min_lr=0.5e-6),\n",
    "    ModelCheckpoint(filepath=f'models/{savename}.ckpt', monitor='val_loss', save_best_only=True)\n",
    "  ]\n",
    "\n",
    "  optimizer = tfa.optimizers.AdamW(learning_rate=0.001, weight_decay=weight_decay)\n",
    "\n",
    "  model.compile(loss='mse', optimizer=optimizer)\n",
    "  return model.fit(x_train, y_train, validation_data=(x_test, y_test),\n",
    "                   epochs=20, batch_size=16, callbacks=callbacks)\n",
    "\n",
    "histories = train_model(autoencoder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict using autoencoder"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  30/3125 [..............................] - ETA: 19:51 - loss: 0.0496"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted = autoencoder.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results side by side\n",
    "### Multiple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare(square_collage(y_test), square_collage(predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Single Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for (original, prediction) in zip(y_test[:3], predicted[:3]): compare(original, prediction)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Badania wpływu parametrów na wyjście i parametry walidujące.\n",
    "Sieć kontrolna to:\n",
    "Sieć bez dropout, bez normalizacji batch'y, bez weight decay oraz o rozmiarze filtrów warstw [64, 128, 256, 512]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def plot_histories(*pairs, parameters):\n",
    "  figure, axes = plt.subplots(ncols=len(parameters), figsize=(10, 3))\n",
    "  (models, histories) = list(zip(*pairs))\n",
    "\n",
    "  labels = [x.name for x in models]\n",
    "  for axis, parameter in zip(axes.reshape(-1), parameters):\n",
    "    for history in histories:\n",
    "      axis.plot(history.history[parameter])\n",
    "    axis.set_ylabel(parameter)\n",
    "    axis.set_xlabel('epoch')\n",
    "    axis.legend(labels, loc='upper right')\n",
    "  plt.show()\n",
    "\n",
    "# Przykładowy plot z parametrami learning_rate, val_loss oraz loss\n",
    "plot_histories((autoencoder, histories), parameters=['lr', 'val_loss', 'loss'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wpływ dropout rate.\n",
    "- badane sieci:\n",
    "  - Sieć I   -- Kontrolna | Brak\n",
    "  - Sieć II  -- 0.05\n",
    "  - Sieć III -- 0.15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layers = [64, 128, 256, 512]\n",
    "dropout_model_base = Autoencoder(layers, use_dropout=0.00)\n",
    "dropout_model_1 = Autoencoder(layers, use_dropout=0.05)\n",
    "dropout_model_2 = Autoencoder(layers, use_dropout=0.15)\n",
    "\n",
    "dropout_model_base.build(input_shape=(None, None, None, 1))\n",
    "dropout_model_1.build(input_shape=(None, None, None, 1))\n",
    "dropout_model_2.build(input_shape=(None, None, None, 1))\n",
    "\n",
    "dropout_pairs = [\n",
    "  (dropout_model_base, train_model(dropout_model_base, savename='dropout-0.00.{epoch:03d}')),\n",
    "  (dropout_model_1, train_model(dropout_model_1, savename='dropout-0.05.{epoch:03d}')),\n",
    "  (dropout_model_2, train_model(dropout_model_2, savename='dropout-0.15.{epoch:03d}')),\n",
    "]\n",
    "plot_histories(*dropout_pairs, parameters=['val_loss', 'loss', 'lr'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "predicted = dropout_model_base.predict(x_test)\n",
    "compare(square_collage(y_test), square_collage(predicted))\n",
    "predicted = dropout_model_1.predict(x_test)\n",
    "compare(square_collage(y_test), square_collage(predicted))\n",
    "predicted = dropout_model_2.predict(x_test)\n",
    "compare(square_collage(y_test), square_collage(predicted))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Wpływ weight decay.\n",
    "- Do badania został wykorzystany rozszerzenie AdamW optymalizator Adama.\n",
    "- badane sieci:\n",
    "  - Sieć I   -- Kontrolna | Brak\n",
    "  - Sieć II  -- 0.10\n",
    "  - Sieć III -- 0.25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layers = [64, 128, 256, 512]\n",
    "decay_model_base = Autoencoder(layers)\n",
    "decay_model_1 = Autoencoder(layers)\n",
    "decay_model_2 = Autoencoder(layers)\n",
    "\n",
    "decay_model_base.build(input_shape=(None, None, None, 1))\n",
    "decay_model_1.build(input_shape=(None, None, None, 1))\n",
    "decay_model_2.build(input_shape=(None, None, None, 1))\n",
    "\n",
    "decay_pairs = [\n",
    "  (decay_model_base, train_model(decay_model_base, weight_decay=0.00, savename='decay-0.00.{epoch:03d}')),\n",
    "  (decay_model_1, train_model(decay_model_1, weight_decay=0.10, savename='decay-0.10.{epoch:03d}')),\n",
    "  (decay_model_2, train_model(decay_model_2, weight_decay=0.25, savename='decay-0.25.{epoch:03d}'))\n",
    "]\n",
    "plot_histories(*decay_pairs, parameters=['val_loss', 'loss', 'lr'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plot_histories(*decay_pairs, parameters=['val_loss', 'loss', 'lr'])\n",
    "predicted = decay_model_base.predict(x_test)\n",
    "compare(square_collage(y_test), square_collage(predicted))\n",
    "predicted = decay_model_1.predict(x_test)\n",
    "compare(square_collage(y_test), square_collage(predicted))\n",
    "predicted = decay_model_2.predict(x_test)\n",
    "compare(square_collage(y_test), square_collage(predicted))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wpływ rozmiaru batch normalization.\n",
    "- Do badania została wykorzystana gotowa wartswa z tensorflow.keras BatchNormalization.\n",
    "- badane sieci:\n",
    "  - Sieć I   -- Kontrolna | Brak\n",
    "  - Sieć II  -- istnieje"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layers = [64, 128, 256, 512]\n",
    "batch_model_no = Autoencoder(layers, use_normalization=False)\n",
    "batch_model_yes = Autoencoder(layers, use_normalization=True)\n",
    "\n",
    "batch_model_no.build(input_shape=(None, None, None, 1))\n",
    "batch_model_yes.build(input_shape=(None, None, None, 1))\n",
    "\n",
    "batch_pairs = [\n",
    "  (batch_model_no, train_model(batch_model_no, savename='batch-no.{epoch:03d}')),\n",
    "  (batch_model_yes, train_model(batch_model_yes, savename='batch-yes.{epoch:03d}'))\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plot_histories(*batch_pairs, parameters=['val_loss', 'loss', 'lr'])\n",
    "predicted = batch_model_yes.predict(x_test)\n",
    "compare(square_collage(y_test), square_collage(predicted))\n",
    "predicted = batch_model_no.predict(x_test)\n",
    "compare(square_collage(y_test), square_collage(predicted))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wpływ rozmiaru sieci.\n",
    "- Do badania została wykorzystana gotowa wartswy z paczki tensorflow.keras.\n",
    "- badane sieci:\n",
    "  - Sieć I   -- Kontrolna | [64, 128, 256, 512]\n",
    "  - Sieć II  -- [32, 64, 128]\n",
    "  - Sieć III -- [32, 64, 128]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filters_model_base = Autoencoder([64, 128, 256, 512])\n",
    "filters_model_1 = Autoencoder([32, 64, 128, 512, 512])\n",
    "filters_model_2 = Autoencoder([32, 64])\n",
    "\n",
    "filters_model_base.build(input_shape=(None, None, None, 1))\n",
    "filters_model_1.build(input_shape=(None, None, None, 1))\n",
    "filters_model_2.build(input_shape=(None, None, None, 1))\n",
    "\n",
    "filters_pairs = [\n",
    "  (filters_model_base, train_model(filters_model_base, savename='filters-medium.{epoch:03d}')),\n",
    "  (filters_model_1, train_model(filters_model_1, savename='filters-bigger.{epoch:03d}')),\n",
    "  (filters_model_2, train_model(filters_model_2, savename='filters-smaller.{epoch:03d}')),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plot_histories(*filters_pairs, parameters=['val_loss', 'loss', 'lr'])\n",
    "predicted = filters_model_base.predict(x_test)\n",
    "compare(square_collage(y_test), square_collage(predicted))\n",
    "predicted = filters_model_1.predict(x_test)\n",
    "compare(square_collage(y_test), square_collage(predicted))\n",
    "predicted = filters_model_2.predict(x_test)\n",
    "compare(square_collage(y_test), square_collage(predicted))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Podsumowanie oraz Doświadczenia\n",
    "- Tensorflow jest wstrętną technologią.\n",
    "- w tym wypadku jakikolwiek decay wplywa negatywnie na jakość obrazów.\n",
    "- Możliwym rozwiązaniem jest większa sieć.\n",
    "- Zmiana architektury bardziej zbliżona do współczesnych modeli jak novel ai, protogen etc. [civilai](https://civitai.com/)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "767d51c1340bd893661ea55ea3124f6de3c7a262a8b4abca0554b478b1e2ff90"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
